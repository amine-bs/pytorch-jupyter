{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765d0684-2616-4b27-a3fd-36ef8e75c529",
   "metadata": {},
   "source": [
    "**PyTorch**\n",
    "\n",
    "Dans ce tutoriel, on va explorer l'implémentation et l'apprentissage d'un réseau de neurones en utlisant PyTorch afin de classifier des images.\n",
    "Pour ce faire, on doit compléter les étapes suivantes:\n",
    "- importation et traitement des données\n",
    "- implémentation du modèle\n",
    "- apprentissage du modèle \n",
    "- validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e94b1-02a6-4cca-9b39-407466f41a60",
   "metadata": {},
   "source": [
    "**Modèles**\n",
    "\n",
    "Le module ``torchvision.models`` propose plusieurs modèles préformés de l'état de l'art qui permettent d'effectuer plusieurs tâches de vision par ordinateur.\n",
    "\n",
    "Ici, on va utiliser le modèle **ResNet18**. Il s'agit d'un réseau de neurones convolutif de 18 couches de profondeur. Les couches profondes utilisent les résidus des couches précédentes, d'où vient son nom *Residual Network*. Cette technique permet d'éviter le problème de *Vanishing Gradient* qui limite la performance des réseaux profonds.\n",
    "\n",
    "Durant l'apprentissage, le réseau traitera l'entrée à travers toutes les couches et retournera une distribution de probabilité sur toutes les classes possibles. Ensuite, on calculera une fonction de perte qui permet d'estimer l'erreur de la prédiction du réseau. Enfin, la propagation des gradients dans le réseau permettra d'optimiser les paramètres des différenetes couches.\n",
    "\n",
    "Pour ce faire, deux fonctions sont indispensables: **forward** et **backward**.\n",
    "- La fonction backward calcule les gradients des paramètres et les fait propager dans le réseau. On définit notre réseau de neurones comme une sous-classe de nn.Module. Cela permet d'hériter la fonction backward. \n",
    "- Ainsi, il suffit de définir la fonction forward qui calcule la sortie du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72b83331-53a8-42c6-a135-b78bc461e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "  def __init__(self, class_num=2, architecture=\"resnet18\", pretrained=True):\n",
    "    super(ResNet,self).__init__()\n",
    "    self.pretrained = pretrained\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    fc_input_dim = model.fc.in_features\n",
    "    #change the dimension of output\n",
    "    model.fc = nn.Linear(fc_input_dim, class_num)\n",
    "    self.model = model\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c76bd2-65e6-480e-9914-3bfb7c123bc4",
   "metadata": {},
   "source": [
    "**Données**\n",
    "\n",
    "Ici, on va utiliser une base de données qui contient des images de plats différents. Notre objectif est de faire une classfication binaire pour vérifier si une image représente une pizza. La base de données contient 1900 images, que l'on va diviser en deux ensembles: **ensemble d'apprentissage** et **ensemble de validation**.\n",
    "Les images sont de type *RGB*, de largeur 384 et d'hauteur 512. \n",
    "\n",
    "On commence par définir des transformations de données. Dans le déploiement, le modèle sera appliqué sur des données du monde réel qui pourraient contenir du bruit. Cela réduit la performance du réseau. Pour résoudre à cela, on utilise une méthode nommée **augmentation des données**. Elle consiste à appliquer des transformations aléatoires sur les données d'apprentissage pour que l'apprentissage soit plus général. Ici, on rogne aléatoirement les images en utilisant la méthode ``TF.crop``. \n",
    "\n",
    "Le modèle ResNet prend en entrée des tenseurs de réels dans l'intervalle [-1, 1]. Donc, on transforme les images à des tenseurs et on les normalisent.\n",
    "\n",
    "PyTorch propose une classe abstraite ``torch.utils.data.Dataset`` qui permet de charger et manoeuvrer la base de données. On prend usage de cette classe et donc on doit surcharger deux méthodes: ``__get_item__`` et ``__len__``.\n",
    "\n",
    "Pour obtenir l'accès aux données et les mettre en mémoire, on utilise la classe ``torch.utils.data.DataLoader``. DataLoader dans Pytorch encapsule un ensemble de données et donne accès aux données sous-jacentes. Ce wrapper contiendra des batchs d'images par taille de batch définie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880ef2e-3918-4ca4-9002-754cb485fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#télécharger les données\n",
    "import boto3\n",
    "import os\n",
    "s3 = boto3.client('s3',endpoint_url='https://minio.lab.sspcloud.fr/')\n",
    "s3.download_file(Bucket=\"mbenxsalha\", Key=\"tutorial/pizza_not_pizza.zip\", Filename=\"data\")\n",
    "!unzip data\n",
    "!rm pizza_not-pizza.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97e3b296-b060-44e3-830f-c25b256a3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
    "\n",
    "def is_image_file(filename):\n",
    "  return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def load_image(path):\n",
    "  img = Image.open(path).convert(\"RGB\")\n",
    "  return img\n",
    "\n",
    "def make_dataset(root):\n",
    "  pizza_path = os.path.join(root,\"pizza\")\n",
    "  not_pizza_path = os.path.join(root,\"not_pizza\")\n",
    "  data = []\n",
    "  for img in os.listdir(pizza_path):\n",
    "    path = os.path.join(pizza_path, img)\n",
    "    data.append((path, 1))\n",
    "\n",
    "  for img in os.listdir(not_pizza_path):\n",
    "    path = os.path.join(not_pizza_path, img)\n",
    "    data.append((path, 0))\n",
    "\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4ffa652-cfdb-4e9e-a5b7-2fc38311bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyTransformer():\n",
    "  def __init__(self, crop):\n",
    "    self.crop = crop\n",
    "\n",
    "  def __call__(self, img, rot=None):\n",
    "    img = TF.resize(img, (256,256))\n",
    "    img = TF.crop(img, self.crop[0], self.crop[1], 224, 224)\n",
    "    img = TF.to_tensor(img)\n",
    "    img = TF.normalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return img\n",
    "\n",
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        imgs = make_dataset(root)\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, lab = self.imgs[index]\n",
    "        img = load_image(path)\n",
    "\n",
    "\n",
    "        # If a custom transform is specified apply that transform\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:  # Otherwise define a random one (random cropping)\n",
    "            top = random.randint(0, 256 - 224)\n",
    "            left = random.randint(0, 256 - 224)\n",
    "            transform = MyTransformer([top, left])\n",
    "            # Apply the transformation\n",
    "            img = transform(img)\n",
    "        return img, lab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b7a5ff9-7131-4f95-9b15-8db84c7ac2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "batch_size = 64\n",
    "data_root = \"shipsnet/shipsnet\"\n",
    "\n",
    "dataset = DatasetGenerator(data_root)\n",
    "train_set_length = int(0.7 * len(dataset))\n",
    "test_set_length = len(dataset) - train_set_length\n",
    "#split the dataset \n",
    "train_set, test_set = random_split(dataset, [train_set_length, test_set_length])\n",
    "#define loaders\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed468fb-028a-420f-96e7-38f7bae4073f",
   "metadata": {},
   "source": [
    "**Optimisation**\n",
    "\n",
    "``torch.optim`` propose plusieurs méthodes de descente de gradient. Ici, on utilisera **la descente de gradient stochastique (SGD)**. \n",
    "On inclut aussi la méthode de **dégradation des pondérations (weight decay)** qui est une technique de régularisation servant à limiter le surapprentissage du réseau.\n",
    "\n",
    "le module ``torch.nn`` propose plusieurs fonctions de perte. Dans ce tutoriel, on utilise **l'entropie croisée** . La minimsation de cette fonction permettra de rapprocher la distribution de probabilité apprise par le modèle à la distribution réelle. \n",
    "\n",
    "On utilise le l'application **cuda** de Nvidia qui permet de paralléliser le calcul en utilisant le processeur graphique (GPU). Cela permet d'optimiser le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06fbafcc-8a90-40a1-9d03-9bb5022a4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class_num = 2\n",
    "\n",
    "ce_loss=nn.CrossEntropyLoss()\n",
    "\n",
    "#set hyperparameters\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "\n",
    "#set device to cuda if nvidia gpu is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "#initialize model\n",
    "model = ResNet(class_num=class_num)\n",
    "model = model.to(device)\n",
    "\n",
    "#define optimizer\n",
    "opt_model = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baac3fb-5a16-4215-90eb-2e65693373f0",
   "metadata": {},
   "source": [
    "**Apprentissage**\n",
    "\n",
    "Pour former le modèle, on doit boucler sur l'itérateur de données, alimenter les entrées au réseau et optimiser les paramètres. \n",
    "\n",
    "``torch.utils.tensorboard`` permet d'enregistrer des logs (la perte à chaque itération par exemple)  de l'apprentissage pour les visualiser après.\n",
    "\n",
    "``tqdm`` permet d'afficher une barre de progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1b2f8db-33ef-4b0e-be97-3f848e4361ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:14<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:15<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:14<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 44/44 [00:14<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "epoch = 10\n",
    "model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "writer = SummaryWriter()\n",
    "for epo in range(1,epoch+1):\n",
    "  correct = 0\n",
    "  print(\"Epoch {}/{} \\n\".format(epo, epoch))\n",
    "  with tqdm(total=len(train_loader), desc=\"Train\") as pb:\n",
    "    for batch_num, (img, img_label) in enumerate(train_loader):\n",
    "      opt_model.zero_grad()\n",
    "      img = img.to(device) \n",
    "      img_label = img_label.to(device)\n",
    "      outputs = model(img)\n",
    "      loss = ce_loss(outputs, img_label)\n",
    "      loss.backward()\n",
    "      opt_model.step()\n",
    "      correct += (torch.argmax(outputs, dim=1)==img_label).sum().item()\n",
    "      writer.add_scalar(\"Loss_recoginition/source\", loss, epo * len(train_loader) + batch_num)\n",
    "      pb.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2386aa4-9425-4ac1-add0-69cd42e785c9",
   "metadata": {},
   "source": [
    "**Evaluation**\n",
    "\n",
    "La dernière étape consiste à évaluer le modèle sur l'ensemble de test.\n",
    "Avant de commencer, on met le modèle sur le mode d'évaluation avec ``model.eval()`` pour geler les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb299ef2-8f8f-41da-9dbf-e9f14a1a07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 19/19 [00:04<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "correct, num_predictions = 0, 0\n",
    "with tqdm(total=len(test_loader), desc=\"Test\") as pb:\n",
    "  model.eval()\n",
    "  for batch_num, (img, img_label) in enumerate(test_loader):\n",
    "    img = img.to(device)\n",
    "    img_label = img_label.to(device)\n",
    "    predictions = model(img)\n",
    "    correct += (torch.argmax(predictions, dim=1)==img_label).sum().item()\n",
    "    num_predictions += predictions.shape[0]\n",
    "    pb.update(1)\n",
    "\n",
    "accuracy = correct / num_predictions\n",
    "print(\"\\n Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aaff46-5d5f-4adf-9cdc-4997993c98b7",
   "metadata": {},
   "source": [
    "**Affichage des logs**\n",
    "\n",
    "Tensorboard enregistre les logs dans un dossier ``runs``.\n",
    "On utilise la commande suivante pour les afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35df1783-38f9-4b97-81c3-6a3849df25e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 904), started 22:10:31 ago. (Use '!kill 904' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-54343b02a11befea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-54343b02a11befea\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea6d20-095b-431e-a91e-786e61ffca89",
   "metadata": {},
   "source": [
    "**Enregistrement du modèle**\n",
    "\n",
    "Enfin, on enregistre le modèle pour l'exploiter après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84e475e7-53e7-4726-84b5-a88903a67cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c171ccf-cb03-4db9-89d1-049f5b95d7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
