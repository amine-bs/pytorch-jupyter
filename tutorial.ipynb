{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "765d0684-2616-4b27-a3fd-36ef8e75c529",
   "metadata": {},
   "source": [
    "**PyTorch**\n",
    "\n",
    "Dans ce tutoriel, on va explorer l'implémentation et l'apprentissage de deux réseaux de neurones en utilisant PyTorch afin de classifier des images.\n",
    "Pour ce faire, on doit compléter les étapes suivantes:\n",
    "- importation et traitement des données\n",
    "- implémentation des modèles\n",
    "- Entrainement\n",
    "- validation et comparaison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a42e94b1-02a6-4cca-9b39-407466f41a60",
   "metadata": {},
   "source": [
    "**Modèles**\n",
    "\n",
    "Le module ``torchvision.models`` propose plusieurs modèles pré-entrainés de l'état de l'art qui permettent d'effectuer plusieurs tâches de vision par ordinateur.\n",
    "\n",
    "Ici, on va utiliser le modèle **ResNet18**. Il s'agit d'un réseau de neurones convolutif de 18 couches de profondeur. Les couches profondes utilisent les résidus des couches précédentes, d'où vient son nom *Residual Network*. Cette technique permet d'éviter le problème de *Vanishing Gradient* qui limite la performance des réseaux profonds.\n",
    "\n",
    "Durant l'apprentissage, le réseau traitera l'entrée à travers toutes les couches et retournera une distribution de probabilité sur toutes les classes possibles. Ensuite, on calculera une fonction de perte qui permet d'estimer l'erreur de la prédiction du réseau. Enfin, la propagation des gradients dans le réseau permettra d'optimiser les paramètres des différenetes couches.\n",
    "\n",
    "Pour ce faire, deux fonctions sont indispensables: **forward** et **backward**.\n",
    "- La fonction backward calcule les gradients des paramètres et les fait propager dans le réseau. On définit notre réseau de neurones comme une sous-classe de nn.Module. Cela permet d'hériter la fonction backward. \n",
    "- Ainsi, il suffit de définir la fonction forward qui calcule la sortie du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b83331-53a8-42c6-a135-b78bc461e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "  def __init__(self, class_num=2, architecture=\"resnet18\", pretrained=True):\n",
    "    super(ResNet,self).__init__()\n",
    "    self.pretrained = pretrained\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    fc_input_dim = model.fc.in_features\n",
    "    #change the dimension of output\n",
    "    model.fc = nn.Linear(fc_input_dim, class_num)\n",
    "    self.model = model\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f327a31b-1411-423e-b64f-654fbe02b9c4",
   "metadata": {},
   "source": [
    "Ensuite, on va construire un autre réseau moins profond que ResNet.\n",
    "On utilisera la fonction **ReLU** pour l'activation de neurones dans toutes les couches sauf pour la dernière où on utilisera **Softmax** qui permet de calculer la distribution de probabilité.\n",
    "\n",
    "Ce réseau est composé de ces couches:\n",
    "- ``torch.nn.Conv2d``: C'est une couche de convolution bidimensionnelle. Elle est caractérisée par son approche locale de traiter les données, ce qui permet d'extraire les motifs et les caractéristiques. \n",
    "- ``torch.nn.MaxPool2d``: Une limitation des couches de convolution est le fait qu'elles marquent une position précise de caractéristiques. Cela signifie que de petits mouvements dans la position de l'objet dans l'image d'entrée entraîneront une sortie différente. Pour résoudre à cela, on utilise une technique de sous-échantillonnage appelée **Pooling** qui donne en sortie un signal de résolution plus petite que celle de l'entrée tout en gardant les éléments importants. Ici, on utilise le **Max Pooling** où on extrait la caractéristique ayant la plus grande amplitude en utilisant une fenêtre mobile.  \n",
    "- ``torch.nn.Linear``: Cette couche est une couche linéaire entièrement connectée. Dans un CNN, on utilise une telle couche généralement en aval du réseau pour calculer les probabilités.\n",
    "- ``torch.nn.BatchNorm2d`` et ``torch.nn.BatchNorm1d(n)``: cette couche est une implémentation de la méthode de **normalisation de lot**. Cette méthode consiste à normaliser chaque lot et d'injecter le résultat dans une fonction affine dont les paramètres sont appris durant la phase d'apprentissage. Cela permet de stabiliser les gradients et ainsi d'accélérer l'apprentissage remarquablement.\n",
    "- ``torch.nn.Dropout``: c'est une implémentation de la technique de **décrochage**. Elle consiste à supprimer temporairement de neurones aléatoires du réseau durant la phase d'apprentissage. Cela permet de réduire le surapprentissage du modèle en évitant les co-adaptations de neurones sur les données d'entrainement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c171ccf-cb03-4db9-89d1-049f5b95d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, class_num=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                   nn.BatchNorm2d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                   nn.BatchNorm2d(128),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2))\n",
    "            \n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                   nn.BatchNorm2d(256),\n",
    "                                   nn.ReLU())\n",
    "        \n",
    "        self.conv6 = nn.Sequential(nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                   nn.BatchNorm2d(256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2))\n",
    "        self.fc1 = nn.Sequential(nn.Linear(200704,1024),\n",
    "                                 nn.BatchNorm1d(1024),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=dropout))\n",
    "        \n",
    "        self.fc2 = nn.Sequential(nn.Linear(1024, 512),\n",
    "                                 nn.BatchNorm1d(512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=dropout))\n",
    "        self.linear = nn.Linear(512, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d933e4ff-01d6-47a1-be2a-83e00cf039bc",
   "metadata": {},
   "source": [
    "**Initialisation de poids et biais**\n",
    "\n",
    "Le module ``torch.nn.init`` propose plusieurs méthodes pour initaliser les poids du réseau. Ici, on utilisera la méthode de Xavier uniforme pour initialiser les poids de couches de convolution. Cette méthode prend en compte le nombre de neurones dans chaque couche et ainsi permet d'adapter les poids initiaux. Cela permet d'éviter certains problèmes de gradients qu'une initialisation complètement aléatoire pourrait engendrer dans les premières étapes d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff92fc8-c844-45c4-8bd2-3dccf643e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.01)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.01)\n",
    "        m.bias.data.normal_(0.0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c76bd2-65e6-480e-9914-3bfb7c123bc4",
   "metadata": {},
   "source": [
    "**Données**\n",
    "\n",
    "Ici, on va utiliser une base de données qui contient des images de plats différents. Notre objectif est de faire une classfication binaire pour vérifier si une image représente une pizza. La base de données contient 1900 images, que l'on va diviser en deux ensembles: **ensemble d'apprentissage** et **ensemble de validation**.\n",
    "Les images sont de type *RGB*, de largeur 384 et d'hauteur 512. \n",
    "\n",
    "On commence par définir des transformations de données. Dans le déploiement, le modèle sera appliqué sur des données du monde réel qui pourraient contenir du bruit. Cela réduit la performance du réseau. Pour résoudre à cela, on utilise une méthode nommée **augmentation des données**. Elle consiste à appliquer des transformations aléatoires sur les données d'apprentissage pour que l'apprentissage soit plus général. Ici, on rogne aléatoirement les images en utilisant la méthode ``TF.crop``. \n",
    "\n",
    "Le modèle ResNet prend en entrée des tenseurs de réels dans l'intervalle [-1, 1]. Donc, on transforme les images à des tenseurs et on les normalisent.\n",
    "\n",
    "PyTorch propose une classe abstraite ``torch.utils.data.Dataset`` qui permet de charger et manoeuvrer la base de données. On prend usage de cette classe et donc on doit surcharger deux méthodes: ``__get_item__`` et ``__len__``.\n",
    "\n",
    "Pour obtenir l'accès aux données et les mettre en mémoire, on utilise la classe ``torch.utils.data.DataLoader``. DataLoader dans Pytorch encapsule un ensemble de données et donne accès aux données sous-jacentes. Ce wrapper contiendra des batchs d'images par taille de batch définie.\n",
    "\n",
    "Les données sont disponibles dans le bucket ``mbenxsalha`` sous le dossier ``diffusion/pizza-not-pizza``. On va utiliser la bibliothèque Python ``boto3`` pour les lire directement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e3b296-b060-44e3-830f-c25b256a3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import boto3\n",
    "\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP']\n",
    "\n",
    "def is_image_file(filename):\n",
    "  return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def load_image(key, bucket=\"mbenxsalha\"):\n",
    "  s3 = boto3.client('s3',endpoint_url='https://minio.lab.sspcloud.fr/')\n",
    "  data = s3.get_object(Bucket=bucket, Key=key)\n",
    "  img = Image.open(data[\"Body\"]).convert(\"RGB\")\n",
    "  return img\n",
    "\n",
    "def make_dataset(root=\"diffusion/pizza-not-pizza\"):\n",
    "  s3 = boto3.client('s3',endpoint_url='https://minio.lab.sspcloud.fr/')\n",
    "  data = []\n",
    "                 \n",
    "  pizza_root = os.path.join(root, \"pizza\")\n",
    "  for img in s3.list_objects(Bucket=\"mbenxsalha\", Prefix=pizza_root)[\"Contents\"]:\n",
    "    key = img[\"Key\"]\n",
    "    if is_image_file(key):\n",
    "        data.append((key, 1))\n",
    "                 \n",
    "  not_pizza_root = os.path.join(root, \"not_pizza\")\n",
    "  for img in s3.list_objects(Bucket=\"mbenxsalha\", Prefix=not_pizza_root)[\"Contents\"]:\n",
    "    key = img[\"Key\"]\n",
    "    if is_image_file(key):\n",
    "        data.append((key, 0))\n",
    "        \n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ffa652-cfdb-4e9e-a5b7-2fc38311bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyTransformer():\n",
    "  def __init__(self, crop):\n",
    "    self.crop = crop\n",
    "\n",
    "  def __call__(self, img, rot=None):\n",
    "    img = TF.resize(img, (256,256))\n",
    "    img = TF.crop(img, self.crop[0], self.crop[1], 224, 224)\n",
    "    img = TF.to_tensor(img)\n",
    "    img = TF.normalize(img, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    return img\n",
    "\n",
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        imgs = make_dataset(root)\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, lab = self.imgs[index]\n",
    "        img = load_image(path)\n",
    "\n",
    "\n",
    "        # If a custom transform is specified apply that transform\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:  # Otherwise define a random one (random cropping)\n",
    "            top = random.randint(0, 256 - 224)\n",
    "            left = random.randint(0, 256 - 224)\n",
    "            transform = MyTransformer([top, left])\n",
    "            # Apply the transformation\n",
    "            img = transform(img)\n",
    "        return img, lab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7a5ff9-7131-4f95-9b15-8db84c7ac2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "batch_size = 64\n",
    "data_root = \"diffusion/pizza-not-pizza\"\n",
    "\n",
    "dataset = DatasetGenerator(data_root)\n",
    "train_set_length = int(0.7 * len(dataset))\n",
    "test_set_length = len(dataset) - train_set_length\n",
    "#split the dataset \n",
    "train_set, test_set = random_split(dataset, [train_set_length, test_set_length])\n",
    "#define loaders\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fed468fb-028a-420f-96e7-38f7bae4073f",
   "metadata": {},
   "source": [
    "**Optimisation**\n",
    "\n",
    "``torch.optim`` propose plusieurs méthodes de descente de gradient. Ici, on utilisera **la descente de gradient stochastique (SGD)**. \n",
    "On inclut aussi la méthode de **dégradation des pondérations (weight decay)** qui est une technique de régularisation servant à limiter le surapprentissage du réseau.\n",
    "\n",
    "Le module ``torch.nn`` propose plusieurs fonctions de perte. Dans ce tutoriel, on utilise **l'entropie croisée** . La minimsation de cette fonction permettra de rapprocher la distribution de probabilité apprise par le modèle à la distribution réelle. \n",
    "\n",
    "On utilise le l'application **cuda** de Nvidia qui permet de paralléliser le calcul en utilisant le processeur graphique (GPU). Cela permet d'optimiser le temps d'exécution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fbafcc-8a90-40a1-9d03-9bb5022a4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class_num = 2\n",
    "\n",
    "ce_loss=nn.CrossEntropyLoss()\n",
    "\n",
    "#set hyperparameters\n",
    "lr = 0.001\n",
    "weight_decay = 0.0005\n",
    "epoch = 20\n",
    "\n",
    "#set device to cuda if nvidia gpu is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#initialize models\n",
    "\n",
    "resnet = ResNet(class_num=class_num)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "network = Network(class_num=class_num)\n",
    "network = network.to(device)\n",
    "network.apply(weights_init)\n",
    "\n",
    "\n",
    "#define optimizers\n",
    "opt_resnet = optim.SGD(resnet.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "opt_network = optim.SGD(network.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3baac3fb-5a16-4215-90eb-2e65693373f0",
   "metadata": {},
   "source": [
    "**Apprentissage**\n",
    "\n",
    "Pour entrainer le modèle, on doit boucler sur l'itérateur de données, alimenter les entrées aux réseaux et optimiser les paramètres. \n",
    "\n",
    "``tqdm`` permet d'afficher une barre de progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2f8db-33ef-4b0e-be97-3f848e4361ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss_resnet, loss_network = [], []\n",
    "resnet.train()\n",
    "network.train\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "for epo in range(1,epoch+1):\n",
    "  correct_resnet, correct_network = 0, 0\n",
    "  print(\"Epoch {}/{} \\n\".format(epo, epoch))\n",
    "  with tqdm(total=len(train_loader), desc=\"Train\") as pb:\n",
    "    for batch_num, (img, img_label) in enumerate(train_loader):\n",
    "      opt_resnet.zero_grad()\n",
    "      opt_network.zero_grad()\n",
    "        \n",
    "      img = img.to(device) \n",
    "      img_label = img_label.to(device)\n",
    "        \n",
    "      outputs = resnet(img)\n",
    "      correct_resnet += (torch.argmax(outputs, dim=1)==img_label).sum().item()\n",
    "      loss = ce_loss(outputs, img_label)\n",
    "      loss.backward()\n",
    "      loss_resnet.append(loss)\n",
    "        \n",
    "      outputs = network(img)\n",
    "      correct_network += (torch.argmax(outputs, dim=1)==img_label).sum().item()\n",
    "      loss = ce_loss(outputs, img_label)\n",
    "      loss.backward()\n",
    "      loss_network.append(loss)\n",
    "        \n",
    "      opt_resnet.step()\n",
    "      opt_network.step()\n",
    "      pb.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2386aa4-9425-4ac1-add0-69cd42e785c9",
   "metadata": {},
   "source": [
    "**Evaluation**\n",
    "\n",
    "La dernière étape consiste à évaluer le modèle sur l'ensemble de test.\n",
    "Avant de commencer, on met le modèle sur le mode d'évaluation avec ``model.eval()`` pour geler les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb299ef2-8f8f-41da-9dbf-e9f14a1a07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "correct_resnet, correct_network, num_predictions = 0, 0, 0\n",
    "with tqdm(total=len(test_loader), desc=\"Test\") as pb:\n",
    "  resnet.eval()\n",
    "  network.eval()\n",
    "  for batch_num, (img, img_label) in enumerate(test_loader):\n",
    "    img = img.to(device)\n",
    "    img_label = img_label.to(device)\n",
    "    predictions = resnet(img)\n",
    "    correct_resnet += (torch.argmax(predictions, dim=1)==img_label).sum().item()\n",
    "    predictions = network(img)\n",
    "    correct_network += (torch.argmax(predictions, dim=1)==img_label).sum().item()\n",
    "    num_predictions += predictions.shape[0]\n",
    "    pb.update(1)\n",
    "\n",
    "accuracy_resnet = correct_resnet / num_predictions\n",
    "accuracy_network = correct_network / num_predictions\n",
    "print(\"\\n ResNet's Accuracy: {} \\n Our network's accuracy: {}\".format(accuracy_resnet, accuracy_network))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80592b85-b995-4474-a93a-3c9a83bd958d",
   "metadata": {},
   "source": [
    "On voit que la précision de ResNet est beaucoup plus haute que celle de notre réseau. Cela s'explique par le fait que ResNet est prétrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5732104a-16d5-4af5-8668-e31532dd5fc3",
   "metadata": {},
   "source": [
    "Ici, on affiche l'évolution de la perte durant l'apprentissage pour chaque modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a9fc4-c346-4054-bb12-465b191fcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "iterations = list(range(len(loss_resnet)))\n",
    "plt.plot(iterations, loss_network, label=\"Network loss\")\n",
    "plt.plot(iterations, loss_resnet, label=\"ResNet loss\")\n",
    "plt.legend()\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea6d20-095b-431e-a91e-786e61ffca89",
   "metadata": {},
   "source": [
    "**Enregistrement du modèle**\n",
    "\n",
    "Enfin, on enregistre les modèle pour les exploiter après"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e475e7-53e7-4726-84b5-a88903a67cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), \"network.pth\")\n",
    "torch.save(resnet.state_dict(), \"resnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9542dd7b953ad8a15b001f77d82648cfda59701cf2c2b565b7c59e3c6c6ed16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
